{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from itertools import groupby\n",
    "import copy\n",
    "import time\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the data and normalizing the x variable to between 0 and 1\n",
    "iris = pd.DataFrame(pd.read_csv(\"iris.csv\"))\n",
    "x_data = iris.iloc[:,0:4]\n",
    "y_data = iris.iloc[:,4:5]\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_data = pd.DataFrame(min_max_scaler.fit_transform(x_data))\n",
    "\n",
    "#splitting into test and train sets\n",
    "x_train_orig, x_test, y_train_orig, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_orig, y_train_orig, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to generate random starting trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to define random starting tree or assign points to a given tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_tree(x, y, method, given_splits = \"missing\", given_cutoffs = \"missing\"):\n",
    "\n",
    "    #calculate a randomized tree if method is 0, otherwise classify points if tree given\n",
    "    if method == 0:\n",
    "        #holding the tree structure\n",
    "        splits = []\n",
    "        cutoffs = []\n",
    "        \n",
    "        #iterate to generate all of the split nodes randomly\n",
    "        p = len(x_train.columns)\n",
    "        depth = random.randint(math.floor(p/2),p)\n",
    "        tot_split = 2 ** (depth) - 1\n",
    "\n",
    "        #creating list of parent nodes to use to check if a parent node has an early leaf\n",
    "        parent_node = [0]\n",
    "        for i in range(2 ** depth - 1):\n",
    "            parent_node += [i, i]\n",
    "            \n",
    "        for split in range(tot_split):\n",
    "            #checking if the parent node of this split is already an early leaf\n",
    "            if split != 0 and splits[parent_node[split]] == [\"early_leaf\", \"early_leaf\"]:\n",
    "                splits.append([\"early_leaf\", \"early_leaf\"])\n",
    "                cutoffs.append(\"early_leaf\")\n",
    "            else:\n",
    "                #potentially adding early leaf randomly\n",
    "                if random.uniform(0,1) < 0.1:\n",
    "                    splits.append([\"early_leaf\", \"early_leaf\"])\n",
    "                    cutoffs.append(\"early_leaf\")\n",
    "                #otherwise create real split instead of early leaf\n",
    "                else:\n",
    "                    #save random split var and cutoff to list\n",
    "                    idx = random.randint(0,p-1)\n",
    "                    min_value = x.iloc[:,idx].min()\n",
    "                    max_value = x.iloc[:,idx].max()\n",
    "                    cut_off = random.uniform(max_value, min_value)\n",
    "\n",
    "                    #making formation easy to alter for later hyperplane usage\n",
    "                    splits.append([idx, 1])\n",
    "                    cutoffs.append(cut_off)\n",
    "    else:\n",
    "        splits = given_splits\n",
    "        cutoffs = given_cutoffs\n",
    "        tot_split = len(splits)\n",
    "        depth = int(math.log2(tot_split + 1))\n",
    "        #creating list of parent nodes to use to check if a parent node has an early leaf\n",
    "        parent_node = [0]\n",
    "        for i in range(2 ** depth - 1):\n",
    "            parent_node += [i, i]\n",
    "        \n",
    "    #calculating the leaf nodes points are assigned to\n",
    "    assignments = []\n",
    "    pts = []\n",
    "    leaf_tracks = []\n",
    "    for i in range(x.shape[0]):\n",
    "        #point number, passing in point, starting node, split info, cutoff info, minimum number node for index of a leaf\n",
    "        leaf_num = assign_leaf(x.iloc[i,:], 0, splits, cutoffs, tot_split)\n",
    "        pts.append(i)\n",
    "        leaf_tracks.append(leaf_num)\n",
    "    assignments.append(pts)\n",
    "    assignments.append(leaf_tracks)\n",
    "        \n",
    "    #finding the classification of each leaf by majority\n",
    "    decisions = leaf_classification(assignments, y)\n",
    "    \n",
    "    #with the assignment of each point and the decision of each leaf, predict each points assignment\n",
    "    decision_by_point = []\n",
    "    for i in range(len(assignments[0])):\n",
    "        decision_by_point.append(decisions[assignments[1][i]])\n",
    "    assignments.append(decision_by_point)\n",
    "    \n",
    "    #returning the results\n",
    "    return splits, cutoffs, assignments, decisions, parent_node, depth, tot_split\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigns points to a given tree, called by random_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_leaf(point, splt_indx, splits, cutoffs, leaf_indx):\n",
    "    #reading in the list of parameters and their coefficients to evaluate versus the cutoff\n",
    "    splt_list = splits[splt_indx]\n",
    "    cur_cutoff = cutoffs[splt_indx]\n",
    "    \n",
    "    #calculating the current value for the given point\n",
    "    tot_val = 0\n",
    "    #multiplying the value of the point by its coefficient in the split list to check for which direction it goes\n",
    "    for i in range(int(len(splt_list) / 2)):\n",
    "        col_num = splt_list[2*i]\n",
    "        coeff = splt_list[2*i+1]\n",
    "        #dont bother if its an early leaf\n",
    "        if col_num == \"early_leaf\":\n",
    "            tot_val = \"early_leaf\"\n",
    "            break\n",
    "        else:\n",
    "            tot_val += point[col_num] * coeff\n",
    "    if tot_val == \"early_leaf\" or cur_cutoff == \"early_leaf\":\n",
    "        return splt_indx\n",
    "    #comparing value to current cutoff and assigning to upper or lower leaf, finding next node to visit\n",
    "    elif tot_val >= cur_cutoff:\n",
    "        next_node = 2 * splt_indx + 2\n",
    "    else:\n",
    "        next_node = 2 * splt_indx + 1\n",
    "        \n",
    "    #if next node is leaf, terminate, otherwise recursion until find leaf node\n",
    "    if next_node >= leaf_indx:\n",
    "        #returning assigned leaf number\n",
    "        return next_node\n",
    "    else:\n",
    "        return assign_leaf(point, next_node, splits, cutoffs, leaf_indx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decides leaf decisions, called by random_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaf_classification(assign, y):\n",
    "    #splitting into sets of the points and their assignments\n",
    "    assignments = assign[1]\n",
    "    pts = assign[0]\n",
    "    \n",
    "    #finding the unique leaves represented\n",
    "    cur_leaves = list(set(assignments))\n",
    "    \n",
    "    #finding the count of each group per leaf and assigning the leaf its majority classification\n",
    "    classification = []\n",
    "    #for each leaf we are checking\n",
    "    for leaf in cur_leaves:\n",
    "        #for all the points in our dataset\n",
    "        indices = []\n",
    "        for idx in range(len(pts)):\n",
    "            #keep track of which points are in this leaf\n",
    "            if assignments[idx] == leaf:\n",
    "                indices.append(idx)\n",
    "        #we know all points in leaf, find majority decision and assign it\n",
    "        pts_left = y.iloc[indices]\n",
    "        decision = pts_left.iloc[:,0].max()\n",
    "        classification.append(leaf)\n",
    "        classification.append(decision)\n",
    "    \n",
    "    #return the results as a dictionary\n",
    "    return {classification[i]: classification[i + 1] for i in range(0, len(classification), 2)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous functions to help with others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find the baseline misclassified error\n",
    "def baseline_error(y_true, y_pred):\n",
    "    tot = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] != y_pred[i]:\n",
    "            tot += 1\n",
    "    return tot\n",
    "\n",
    "#optional beta, if included the loss function will have the 0 norm penalizer\n",
    "def loss_function(y_true, y_pred, base_err, tot_splits, splits, alpha, beta = 0):\n",
    "    #finding the total number of misclassified points in the new tree\n",
    "    tot_points = len(y_true)\n",
    "    L = 0\n",
    "    for point in range(tot_points):\n",
    "        if y_true[point] != y_pred[point]:\n",
    "            L += 1\n",
    "    \n",
    "    #finding the amount of variables used in each split for total number used\n",
    "    tot_vars_used = 0\n",
    "    for split in splits:\n",
    "        if split[0] == \"early_leaf\":\n",
    "            continue\n",
    "        else:\n",
    "            vars_used = np.count_nonzero(split[1::2])\n",
    "            tot_vars_used += vars_used\n",
    "    \n",
    "    #returning the loss function\n",
    "    return (L / base_err) + alpha * tot_splits + beta * tot_vars_used\n",
    "\n",
    "#function to return list of all parents of a leaf node for the RR function to use\n",
    "def children(orig_node, cur_node, parent_nodes, all_children):\n",
    "    #append new node the list of children\n",
    "    all_children.append(int(cur_node))\n",
    "    #Finding the next nodes to the left and right\n",
    "    cur_node_right = 2 * cur_node + 2\n",
    "    cur_node_left = 2 * cur_node + 1\n",
    "    \n",
    "    #checking if they are in the tree, if not add them\n",
    "    if int(cur_node_right) not in set(all_children) and cur_node_right <= len(parent_nodes) - 1:\n",
    "        return children(orig_node, cur_node_right, parent_nodes, all_children)\n",
    "    if int(cur_node_left) not in set(all_children) and cur_node_left <= len(parent_nodes) - 1:\n",
    "        return children(orig_node, cur_node_left, parent_nodes, all_children)\n",
    "    \n",
    "    #if both of the splits are in the tree, go up another level and try again\n",
    "    if cur_node % 2 == 0:\n",
    "        cur_node_up = (cur_node - 2) / 2\n",
    "    else:\n",
    "        cur_node_up = (cur_node - 1) / 2\n",
    "    #as long as we have more branches to check and are not above our original node, check them\n",
    "    if cur_node_up >= orig_node:\n",
    "        return children(orig_node, cur_node_up, parent_nodes, all_children)\n",
    "    \n",
    "    #return final list of children\n",
    "    return set(all_children)                                                 \n",
    "                                                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the left or right subtree from a given node for random restarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the left or right subtree of a node\n",
    "def delete_node(node_num, splits, cutoffs, parent_node, decisions, split_direction):\n",
    "    #branch node\n",
    "    if len(splits) > 1:\n",
    "        #left split\n",
    "        if split_direction == 0:\n",
    "            sub_tree_start = 2 * node_num + 1\n",
    "        #right split\n",
    "        else:\n",
    "            sub_tree_start = 2 * node_num + 2\n",
    "\n",
    "        #getting subtree indexes\n",
    "        subtree_indx = list(children(sub_tree_start, sub_tree_start, parent_node, []))\n",
    "        \n",
    "        new_splits = []\n",
    "        new_cutoffs = []\n",
    "        for i, node in enumerate(subtree_indx):\n",
    "            if node < len(splits):\n",
    "                new_splits.append(splits[node])\n",
    "                new_cutoffs.append(cutoffs[node])\n",
    "        return new_splits, new_cutoffs, decisions\n",
    "        \n",
    "    #if it is a final split node change to an early leaf\n",
    "    else:\n",
    "        splits[0] = [\"early_leaf\", \"early_leaf\"]\n",
    "        cutoffs[0] = \"early_leaf\"\n",
    "        \n",
    "        return splits, cutoffs, decisions\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to find optimal splits within the random_restart function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General function to update the tree after split changes are made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_tree(x, y, first_node, parent_nodes, splits, cutoffs, new_splits, new_cutoffs, took):\n",
    "        #if parallel change, update directly\n",
    "        if took == 1 or took == 4:\n",
    "            splits[first_node] = new_splits[0]\n",
    "            cutoffs[first_node] = new_cutoffs[0]\n",
    "        #if left or right subtree, update here\n",
    "        else:\n",
    "            #finding parent node of starting split\n",
    "            start_node = parent_nodes[first_node]\n",
    "            all_children_nodes = list(children(start_node, start_node, parent_nodes, []))\n",
    "            all_children_nodes = all_children_nodes[0:int(len(all_children_nodes) / 2)]\n",
    "            #only keeping the split nodes (excluding children)\n",
    "            sub_children = list(children(first_node, first_node, parent_nodes, []))\n",
    "            sub_children = sub_children[0:int(len(sub_children) / 2)]\n",
    "            #change nodes in original to corresponding ne\n",
    "            i = 0\n",
    "            for node in (all_children_nodes):\n",
    "                if node in sub_children:\n",
    "                    if i < len(new_splits):\n",
    "                        splits[node] = new_splits[i]\n",
    "                        cutoffs[node] = new_cutoffs[i]\n",
    "                        i +=1\n",
    "                    else:\n",
    "                        splits[node] = [\"early_leaf\", \"early_leaf\"]\n",
    "                        cutoffs[node] = \"early_leaf\"\n",
    "                    \n",
    "        _, _, assign, decisions, _, _, _ = random_tree(x, y, 1, given_splits = splits, given_cutoffs = cutoffs)\n",
    "        return splits, cutoffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the optimal parallel splits amongst the critical cutoff values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass in the subtree to optimize, always will change the first splits / cutoffs\n",
    "def best_parallel_split(x, y, splits, cutoffs, decisions, minleafsize, base_error, alpha, beta):\n",
    "    n, p = x.shape\n",
    "    error_best = math.inf\n",
    "    best_splits = copy.deepcopy(splits)\n",
    "    best_cutoffs = copy.deepcopy(cutoffs)\n",
    "    best_decisions = copy.deepcopy(decisions)\n",
    "    \n",
    "    #loop over all dimensions\n",
    "    for j in range(p):\n",
    "        x_vals = x.iloc[:,j]\n",
    "        x_vals = sorted(list(x_vals))\n",
    "        \n",
    "        #loop over all possible split placements (between x values)\n",
    "        for i in range(n - 1):\n",
    "            new_split_cutoff = 0.5 * (x_vals[i] + x_vals[i+1])\n",
    "            \n",
    "            #updating for new cutoff and split variable\n",
    "            cutoffs[0] = new_split_cutoff\n",
    "            splits[0] = [j, 1]\n",
    "            \n",
    "            #finding where new point assignments are\n",
    "            _, _, assigns, decisions, _, _, tot_splits = random_tree(x, y, 1, given_splits = splits, given_cutoffs = cutoffs)\n",
    "            min_leaf_num = min([len(list(group)) for key, group in groupby(sorted(assigns[1]))])\n",
    "            \n",
    "            #if min leaf size constraint held, make the switch\n",
    "            if min_leaf_num >= minleafsize:\n",
    "                cur_error = loss_function(list(y.iloc[:,0]), assigns[2], base_error, tot_splits, splits, alpha, beta)\n",
    "                if cur_error < error_best:\n",
    "                    best_splits = copy.deepcopy(splits)\n",
    "                    best_cutoffs = copy.deepcopy(cutoffs)\n",
    "                    best_decisions = copy.deepcopy(decisions)\n",
    "                    error_best = cur_error\n",
    "                    \n",
    "                    \n",
    "    #returning the best split\n",
    "    return best_splits, best_cutoffs, best_decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finding the best hyperplane splits amongst the ciritcal values U and deletion values W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def besthyperplanesplit(x, y, splits, cutoffs, minleafsize, base_error, alpha, beta):\n",
    "    #getting dimensions of the data for later use\n",
    "    n, p = x.shape\n",
    "    best_splits = copy.deepcopy(splits)\n",
    "    best_cutoffs = copy.deepcopy(cutoffs)\n",
    "    \n",
    "    \n",
    "    #editting the split format now to make for easier manipulation later\n",
    "    #checking if current split is an early leaf to initialize changing_split correctly\n",
    "    if splits[0] == [\"early_leaf\", \"early_leaf\"]:\n",
    "        changing_split = []\n",
    "        for dimension in range(p):\n",
    "            changing_split += [dimension, 0]\n",
    "    else:    \n",
    "        vars_used_split = splits[0][::2]\n",
    "        coefs_used_split = splits[0][1::2]\n",
    "        changing_split = []\n",
    "        for dimension in range(p):\n",
    "            if dimension not in set(vars_used_split):\n",
    "                changing_split += [dimension, 0]\n",
    "            else:\n",
    "                indx = vars_used_split.index(dimension)\n",
    "                changing_split += [dimension, coefs_used_split[indx]]\n",
    "    best_changing_split = copy.deepcopy(changing_split)\n",
    "    \n",
    "    #finding initial input error\n",
    "    _, _, assigns, decisions, _, _, tot_splits = random_tree(x, y, 1, given_splits = splits, given_cutoffs = cutoffs)\n",
    "    error_best = loss_function(list(y.iloc[:,0]), assigns[2], base_error, tot_splits, splits, alpha, beta)\n",
    "    prev_error = error_best + 1\n",
    "    \n",
    "    #starting the while loop to find the best hyperplane split\n",
    "    while error_best != prev_error:\n",
    "        prev_error = error_best #not sure about this line\n",
    "        \n",
    "        #checking for a new hyperplane split against all dimensions\n",
    "        for i in range(p):\n",
    "            \n",
    "            #calculating critical values for perturbating\n",
    "            U = []\n",
    "            for j in range(n):\n",
    "                #getting the jth point of the ith dimension to calculate the corresponding V and U's\n",
    "                if x.iloc[j, i] != 0:\n",
    "                    if cutoffs[0] == \"early_leaf\":\n",
    "                        cutoffs[0] = 0\n",
    "                        V = sum(changing_split[2*k+1] * x.iloc[j,k] - cutoffs[0] for k in range(int(len(changing_split)/2)))\n",
    "                    else:\n",
    "                        V = sum(changing_split[2*k+1] * x.iloc[j,k] - cutoffs[0] for k in range(int(len(changing_split)/2)))\n",
    "                    U.append((changing_split[2*i+1] * x.iloc[j, i] - V) / x.iloc[j, i])\n",
    "            U = sorted(U)\n",
    "            \n",
    "            #looping over all split placements\n",
    "            for j in range(len(U) - 1):\n",
    "                c = 0.5 * (U[j] + U[j+1])\n",
    "                changing_split[2*i+1] = c\n",
    "                splits[0] = changing_split\n",
    "                \n",
    "                #finding where new point assignments are\n",
    "                _, _, assigns, decisions, _, _, tot_splits = random_tree(x, y, 1, given_splits = splits, given_cutoffs = cutoffs)\n",
    "                min_leaf_num = min([len(list(group)) for key, group in groupby(sorted(assigns[1]))])\n",
    "                \n",
    "                #if min leaf size constraint held, make the switch\n",
    "                if min_leaf_num >= minleafsize:\n",
    "                    cur_error = loss_function(list(y.iloc[:,0]), assigns[2], base_error, tot_splits, splits, alpha, beta)\n",
    "                    if cur_error < error_best:\n",
    "                        best_changing_split = copy.deepcopy(changing_split)\n",
    "                        best_splits = copy.deepcopy(splits)\n",
    "                        best_cutoffs = copy.deepcopy(cutoffs)\n",
    "                        error_best = cur_error\n",
    "            \n",
    "            #updating splits to test reduction of variables on to only be the best found through split placements procedure\n",
    "            changing_split = copy.deepcopy(best_changing_split)\n",
    "            \n",
    "            #checking if a split should be deleted to improve error\n",
    "            #check if dimension is still in the split\n",
    "            if changing_split[2*i+1] != 0:\n",
    "                #calculating the critical values for deletion\n",
    "                W = []\n",
    "                #finding critical deletion values for all points\n",
    "                for j in range(n):\n",
    "                    V = sum(changing_split[2*k+1] * x.iloc[j,k] - cutoffs[0] for k in range(int(len(changing_split)/2)))\n",
    "                    W.append(V + cutoffs[0] - changing_split[2*i+1])\n",
    "                W = sorted(W)\n",
    "                \n",
    "                #finding best W critical value to use for b\n",
    "                changing_split[2*i+1] = 0\n",
    "                for j in range(len(W) - 1):\n",
    "                    b = 0.5*(W[j] + W[j+1]) \n",
    "                    cutoffs[0] = b\n",
    "                    splits[0] = changing_split\n",
    "                    \n",
    "                    #finding where new point assignments are\n",
    "                    _, _, assigns, decisions, _, _, tot_splits = random_tree(x, y, 1, given_splits = splits, given_cutoffs = cutoffs)\n",
    "                    min_leaf_num = min([len(list(group)) for key, group in groupby(sorted(assigns[1]))])\n",
    "\n",
    "                    #if min leaf size constraint held, make the switch\n",
    "                    if min_leaf_num >= minleafsize:\n",
    "                        cur_error = loss_function(list(y.iloc[:,0]), assigns[2], base_error, tot_splits, splits, alpha, beta)\n",
    "                        if cur_error < error_best:\n",
    "                            best_changing_split = copy.deepcopy(changing_split)\n",
    "                            best_splits = copy.deepcopy(splits)\n",
    "                            best_cutoffs = copy.deepcopy(cutoffs)\n",
    "                            error_best = cur_error\n",
    "            \n",
    "            #updating splits and cutoffs used for next iteration only to be best found through deletion procedure\n",
    "            changing_split = copy.deepcopy(best_changing_split)\n",
    "            cutoffs = copy.deepcopy(best_cutoffs)\n",
    "                    \n",
    "    #returning the results\n",
    "    return best_splits, best_cutoffs\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best option between parallel, hyperplane, left, or right subtree splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizenodehyper(x, y, splits, cutoffs, decisions, base_error, alpha, beta, minleafsize):\n",
    "    #finding the initial error of input tree\n",
    "    _, _, assign, _, parent_node, _, tot_splits = random_tree(x, y, 1, given_splits = splits, given_cutoffs = cutoffs)\n",
    "    error_best = loss_function(list(y.iloc[:,0]), assign[2], base_error, tot_splits, splits, alpha, beta)\n",
    "    final_splits, final_cutoffs, final_decisions, took = splits, cutoffs, decisions, 0\n",
    "    #getting the best parallel split option\n",
    "    parallel_splits, parallel_cutoffs, parallel_decisions = best_parallel_split(x, y, splits, cutoffs, decisions, minleafsize, base_error, alpha, beta)\n",
    "    _, _, assign_parallel, parallel_decisions, _, _, tot_splits = random_tree(x, y, 1, given_splits = parallel_splits, given_cutoffs = parallel_cutoffs)\n",
    "    parallel_error = loss_function(list(y.iloc[:,0]), assign_parallel[2], base_error, tot_splits, parallel_splits, alpha, beta)\n",
    "    if parallel_error < error_best:\n",
    "        final_splits, final_cutoffs, final_decisions, took = parallel_splits, parallel_cutoffs, parallel_decisions, 1\n",
    "        error_best = parallel_error\n",
    "    \n",
    "    #making sure it is feasbile to cut the split out\n",
    "    #getting the left subtree errors\n",
    "    left_subtree, left_cutoffs, left_decisions = delete_node(0, splits, cutoffs, parent_node, decisions, 0)\n",
    "    _, _, assign_left, left_decisions, _, _, tot_splits = random_tree(x, y, 1, given_splits = left_subtree, given_cutoffs = left_cutoffs)\n",
    "    left_error = loss_function(list(y.iloc[:,0]), assign_left[2], base_error, tot_splits, left_subtree, alpha, beta)\n",
    "    #saving left subtree if it is better than current loss\n",
    "    if left_error < error_best:\n",
    "        final_splits, final_cutoffs, final_decisions, took = left_subtree, left_cutoffs, left_decisions, 2\n",
    "        error_best = left_error\n",
    "\n",
    "    #getting right subtree errors\n",
    "    right_subtree, right_cutoffs, right_decisions = delete_node(0, splits, cutoffs, parent_node, decisions, 1)\n",
    "    _, _, assign_right, right_decisions, _, _, tot_splits = random_tree(x, y, 1, given_splits = right_subtree, given_cutoffs = right_cutoffs)\n",
    "    right_error = loss_function(list(y.iloc[:,0]), assign_right[2], base_error, tot_splits, right_subtree, alpha, beta)\n",
    "    #saving right subtree if it is better than current\n",
    "    if right_error < error_best:\n",
    "        final_splits, final_cutoffs, final_decisions, took = right_subtree, right_cutoffs, right_decisions, 3\n",
    "        error_best = right_error\n",
    "    \n",
    "    #beginning hyperplane restarts loop\n",
    "    H = 5\n",
    "    for h in range(H):\n",
    "        if h == 0:\n",
    "            split_start = copy.deepcopy(splits)\n",
    "            cutoffs_start = copy.deepcopy(cutoffs)\n",
    "        else:\n",
    "            #getting a random hyperplane start\n",
    "            split_start = copy.deepcopy(splits)\n",
    "            random_split = []\n",
    "            for i in range(len(x.columns)):\n",
    "                random_split.append(i)\n",
    "                random_split.append(random.uniform(min(x.iloc[:,i]), max(x.iloc[:,i])))\n",
    "            split_start[0] = random_split\n",
    "            \n",
    "            #getting a random cutoff start\n",
    "            cutoffs_start = copy.deepcopy(cutoffs)\n",
    "            max_num = sum(max(x.iloc[:, i]) for i in range(len(x.columns)))\n",
    "            cutoffs_start[0] = random.uniform(-max_num, max_num)\n",
    "        \n",
    "        #getting the best hyperplane split\n",
    "        hyper_splits, hyper_cutoffs = besthyperplanesplit(x, y, split_start, cutoffs_start, minleafsize, base_error, alpha, beta)\n",
    "        _, _, assign_hyper, hyper_decisions, _, _, tot_splits = random_tree(x, y, 1, given_splits = hyper_splits, given_cutoffs = hyper_cutoffs)\n",
    "        hyper_error = loss_function(list(y.iloc[:,0]), assign_hyper[2], base_error, tot_splits, hyper_splits, alpha, beta)\n",
    "        if hyper_error < error_best:\n",
    "            final_splits, final_cutoffs, final_decisions, took = copy.deepcopy(hyper_splits), copy.deepcopy(hyper_cutoffs), copy.deepcopy(hyper_decisions), 4\n",
    "            error_best = copy.deepcopy(hyper_error)\n",
    "\n",
    "    #outputting the best tree found\n",
    "    return final_splits, final_cutoffs, final_decisions, error_best, took"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Restart Master function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_restarts(x, y, num_restarts, alpha, beta, minleafsize):\n",
    "    #creating lists to save the results of the random restart algorithm\n",
    "    saved_errors = []\n",
    "    saved_splits = []\n",
    "    saved_cutoffs = []\n",
    "    saved_decisions = []\n",
    "    \n",
    "    #iterating through each restart for algorithm\n",
    "    for restart_iteration in tqdm(range(num_restarts), desc=\"Training Tree with Alpha: {} and Beta: {}\".format(alpha, beta)):\n",
    "        #generating a random tree to start the algorithm and finding current error\n",
    "        splits, cutoffs, assign, decisions, parent_node, depth, tot_splits = random_tree(x, y, 0)\n",
    "        #generate baseline for loss function calculation\n",
    "        base_err = baseline_error(list(y.iloc[:,0]), assign[2])\n",
    "        #finding loss function value of original random tree\n",
    "        cur_error = loss_function(list(y.iloc[:,0]), assign[2], base_err, tot_splits, splits, alpha, beta)\n",
    "        error_prev = -1\n",
    "        \n",
    "        #iterate until the current and previous errors are the same (no change found in the tree)\n",
    "        while cur_error != error_prev:\n",
    "            #finding loss function on current tree given to function\n",
    "            error_prev = cur_error\n",
    "            \n",
    "            #randomly iterating through all split nodes\n",
    "            nodes = list(range(tot_splits))\n",
    "            random.shuffle(nodes)\n",
    "            all_errors = []\n",
    "            for node in nodes:\n",
    "                orig_splits = copy.deepcopy(splits)\n",
    "                orig_cutoffs = copy.deepcopy(cutoffs)\n",
    "                \n",
    "                #finding points currently assigned to this node by the tree\n",
    "                point_indx = []\n",
    "                for point in range(len(y)):\n",
    "                    #if leaf in current node, keep point\n",
    "                    if assign[1][point] in children(node,node,parent_node, []):\n",
    "                        point_indx.append(point)\n",
    "                #creating set of x and y points left for this node iteration\n",
    "                cur_x = x.iloc[point_indx, :]\n",
    "                cur_y = y.iloc[point_indx]\n",
    "                \n",
    "                #if no points assigned to node, changing node wont help error\n",
    "                if len(cur_x) > 0:\n",
    "                    #getting subtree structure for current node\n",
    "                    subtree_indx = list(children(node, node, parent_node, []))\n",
    "                    new_splits = []\n",
    "                    new_cutoffs = []\n",
    "                    for i, t in enumerate(subtree_indx):\n",
    "                        if t < len(splits):\n",
    "                            new_splits.append(splits[t])\n",
    "                            new_cutoffs.append(cutoffs[t])\n",
    "                    \n",
    "\n",
    "                    #printing local subtree error\n",
    "                    _, _, cur_assign, _, _, _, tot_splits = random_tree(cur_x, cur_y, 1, given_splits = new_splits, given_cutoffs = new_cutoffs)\n",
    "                    subtree_error = loss_function(list(cur_y.iloc[:,0]), cur_assign[2], base_err, tot_splits, new_splits, alpha, beta) \n",
    "\n",
    "                    #now insert function to find best replacement for current node\n",
    "                    final_splits, final_cutoffs, final_decisions, error_best, took = optimizenodehyper(cur_x, cur_y, new_splits, new_cutoffs, decisions, base_err, alpha, beta, minleafsize)\n",
    "                    \n",
    "                    #update original tree with the best new split found in the optimizenodehyper function\n",
    "                    if took != 0:\n",
    "                        splits, cutoffs = update_tree(cur_x, cur_y, node, parent_node, splits, cutoffs, final_splits, final_cutoffs, took)\n",
    "                    _, _, cur_assign, _, _, _, tot_splits = random_tree(cur_x, cur_y, 1, given_splits = splits, given_cutoffs = cutoffs)\n",
    "                    cur_error = loss_function(list(cur_y.iloc[:,0]), cur_assign[2], base_err, tot_splits, splits, alpha, beta)\n",
    "                \n",
    "                #update error of entirely update tree\n",
    "                _, _, cur_assign, _, _, _, tot_splits = random_tree(x, y, 1, given_splits = splits, given_cutoffs = cutoffs)\n",
    "                cur_error = loss_function(list(y.iloc[:,0]), cur_assign[2], base_err, tot_splits, splits, alpha, beta)\n",
    "                #print(\"\\t\\tCurrent Loss Middle:\\t\", cur_error)\n",
    "                if not len(all_errors) == 0 and cur_error > all_errors[-1]:\n",
    "                    splits = copy.deepcopy(orig_splits)\n",
    "                    cutoffs = copy.deepcopy(orig_cutoffs)\n",
    "                else:\n",
    "                    all_errors.append(cur_error)\n",
    "\n",
    "            #update error of entirely update tree\n",
    "            _, _, cur_assign, _, _, _, tot_splits = random_tree(x, y, 1, given_splits = splits, given_cutoffs = cutoffs)\n",
    "            cur_error = loss_function(list(y.iloc[:,0]), cur_assign[2], base_err, tot_splits, splits, alpha, beta)\n",
    "            \n",
    "            #updating the vectors for next iteration\n",
    "            assign = cur_assign\n",
    "            \n",
    "        #once the errors converage and no changes are made to the tree, return our locally optimal tree\n",
    "        #append tree to a list\n",
    "        saved_splits.append(copy.deepcopy(splits))\n",
    "        saved_cutoffs.append(copy.deepcopy(cutoffs))\n",
    "        saved_decisions.append(copy.deepcopy(decisions))\n",
    "        \n",
    "        #append its loss function value to a list\n",
    "        saved_errors.append(cur_error)\n",
    "        \n",
    "    #return the best of all of our locally optimal trees here\n",
    "    #check for the index of the minimum loss function\n",
    "    output_error = min(saved_errors)\n",
    "    indx = saved_errors.index(output_error)\n",
    "    \n",
    "    #return the tree corresponding with that index\n",
    "    return saved_splits[indx], saved_cutoffs[indx], saved_decisions[indx], output_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#running the random restart algorithm\n",
    "time_taken = []\n",
    "validation_accuracy = []\n",
    "parameter_combo = []\n",
    "\n",
    "alphas = [0, 0.1, 0.01, 0.001]\n",
    "betas = [0, 0.33333]\n",
    "for alpha in tqdm(alphas, desc = \"Alpha Progress\"):\n",
    "    for beta in tqdm(betas, desc = \"Beta Progress with Alpha: {}\".format(alpha)):\n",
    "        start = time.time()\n",
    "        splits, cutoffs, decisions, loss_value = random_restarts(x_train, y_train,5,alpha,beta, 1) \n",
    "        end = time.time()\n",
    "        \n",
    "        #saving time it took\n",
    "        time_taken.append(start - end)\n",
    "        \n",
    "        #saving alpha value and beta value for the run\n",
    "        parameter_combo.append([alpha, beta])\n",
    "        \n",
    "        #saving validation accuracy\n",
    "        splits, cutoffs, assign, decisions, parent_node, depth, tot_splits = random_tree(x_valid, y_valid, 1, given_splits = splits, given_cutoffs = cutoffs)\n",
    "        validation_accuracy.append(accuracy_score(y_valid, assign[2]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting final accuracy stats\n",
    "splits, cutoffs, assign, decisions, parent_node, depth, tot_splits = random_tree(x_train_orig, y_train_orig, 1, given_splits = splits, given_cutoffs = cutoffs)\n",
    "in_sample = accuracy_score(y_train_orig, assign[2])\n",
    "splits, cutoffs, assign, decisions, parent_node, depth, tot_splits = random_tree(x_test_orig, y_test_orig, 1, given_splits = splits, given_cutoffs = cutoffs)\n",
    "out_sample = accuracy_score(y_test, assign[2])\n",
    "\n",
    "print(\"In Sample:\\t\", in_sample)\n",
    "print(\"Out Sample:\\t\", out_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
